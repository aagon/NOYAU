#+TITLE : Prise de notes CM 4I401 NOYAU
#+PROPERTY: header-args :mkdirp yes
#+STARTUP: inlineimages

Pierre Sens (pierre.sens@lip6.fr)
4I401

* Informations pratiques

Décalage 1 semaine entre cours et TD.

40 % ER 1 + 60 % ER 2

M.J. Bach, _Conception du système UNIX_


* Cours 1 : 16/09/2019

Le but est de regarder comment les mécanismes sont implémentés (suite du cours NSY103) : on ne programme pas au-dessus du système en utilisant ses API, on regarde comment ces dernières sont implémentées.

Notions :
- Processus comme instance d'un programme géré par l'OS, avec contexte, construction et destruction
- Ordonnancement comme attribution des processeurs aux beaucoup plus nombreux processus
- Les entrées-sorties et le système de gestion de fichiers (et l'implémentation de la notion de fichier)
- La mémoire virtuelle et la mémoire physique, correspondance, cache, défaut, et traduction.

** Machine what ?

Machine est au fond une machine de Neumann :

CPU, mémoire centrale, périphérique, bus système et contrôleurs d'entrée-sortie (des processeurs spécialisés).

*** Les caches :

Registre processeur <1ns
Cache L1 ~1ns
Cache L2 2-3 ns
Cache L3 ????
Mémoire centrale 10-50 ns

Disque 10 ms (1 million de fois plus de temps) (pas SSD, plus rapide)

On peut imaginer plusieurs architectures de cache en cas de multi-coeur (les registres et le cache L1, L2, L3 sont-ils spécifiques à chaque coeur ou commun).

Sur l'architecture canonique actuelle (multi-coeur), on partage à partir du cache L2.

** OS what ?

Un logiciel, un code ("soft") chargé de discuter avec la machine.

Un ensemble de pilotes chargés de commander les périphériques.

La gestion du cache, des processus, des communications interprocessus, de la mémoire, et du système de fichier.

** unix what ?

Système interactif en temps partagé, multi-utilisateur et multi-tâches.

10000 lignes de C (version 6, 1976), fait pour être simple, pour les mini-PC.

Normalisations, la plus importante étant POSIX. Linux, presque totalement POSIX-compliant, réconcilie plus ou moins les différentes versions de unix.

- Temps partagé
- Isolation des contextes mémoire
- Gestion des fichiers

** Process what ?

Exécution, instance d'un programme. Correspond à un contexte mémoire et un contexte processeur (valeurs des registres et des caches).

Le système d'exploitation n'a pas de processus, il vit autour de la zone des processus et il l'enveloppe. En fait, le code de l'OS n'est exécuté qu'appelé par un processus (appel système, trappe, interruption, signal).

Dans le contexte mémoire (il est question ici de la mémoire virtuelle du processus, la mémoire immense que le processus voit, bien supérieur à la mémoire physique de l'ordinateur), il y a le code, les données, la pile, puis un espace vide immense dans lequel on peut entasser pourvu que le langage le permette.

Dans le contexte processeur (apparemment aussi appelé contexte matériel), il y a des registres (le compteur ordinal, le Program Counter, le pointeur de la prochaine instruction à exécuter).

** BIOS what ?

Une espèce de mini-OS qui dialogue avec les différents périphérique, puis il charge l'OS du disque. Il faut un bootstrapper pour charger les différents OS (il charge le bloc 0 d'un disque indiqué, appelé MBR). Le bootloader doit tenir sur ce bloc, il est donc minuscule.


* Cours 2 : 23/09/2019

Le tas est une sous-zone de la section des données.

En vrai, la section de données contient :
- les variables globales
- l'allocation dynamique

Quand un programme a plusieurs instances, on se permet de ne charger qu'une version du code dans la mémoire.

(sous BSD Unix) Une structure commune aux deux processus garde le nombre de processus qui se servent de ce code (pour éviter qu'il soit flush à la fin de l'exécution de l'un d'entre eux). Les processus qui partagent le même code sont chaînés entre eux.

Ce sont les processus qui exécutent le code du système.

** Comment gère-t-on les processus ?

Il existe dans la zone mémoire du noyau une table des processus, qui contient un ensemble de structures.


[insérer ici les images du cours CNAM]
Qu'y a-t-il dans la structure proc ?
- pid
- Le pointeur vers la zone U
- Etat du processus (prêt, en E/S, élu)
- Pointeurs vers plusieurs listes de processus

Qu'y a-t-il dans la zone U ?
- Le bloc de contrôle de processus
- le pointeur vers la structure proc
- uid, gid, etc...

*** Les états du processus

[insérer une image, préférablement du cours de Joelle]


* Cours 3 : 30/09/2019

** Fork, exec, exit
** Les signaux

Les handlers de signaux ne sont pas exécutés en mode noyau, ils ont été écrits par l'utilisateur :

Le mécanisme spécial qui permet de faire en sorte que ce handler soit exécuté en mode utilisateur passe par la manipulation, par le système, de la pile du processus : on sauvegarde la valeur du compteur ordinal, on pose le compteur ordinal sur l'adresse de la fonction handler, et on rétablit à la sortie de la fonction handling.  

#+BEGIN_QUOTE
sendsig()
must prepare the registers and stack of the current process to
invoke the signal handler stored in the process's struct sigacts.
This may include switching to an alternate signal stack specified
by the process.  The previous register, stack, and signal state
are stored in a ucontext_t, which is then copied out to the user's
stack.
#+END_QUOTE

** Les interruptions

Lors du traitement d'une interruption qui manipule des sections critiques de la section noyau de la mémoire ou des registres, on ne doit traiter aucune autre interruption : on masque toutes les interruptions à l'aide de set-priority-level le temps que les ressources critiques finissent d'être traitées.

(il s'agit de la fonction spl qu'on voit dans le code source de UNIX en TD)

** Synchronisation


* Cours 4 : 07/10/2019

** Synchronisation, suite

*** sleep et wakeup

Permet la synchronisation. [déjà vu en TD]

Algorithme de sleep, pendant au code du TD :

[[./CM1/sleep.jpg][Algorithme de sleep]]

Implémentation de sleep :

#+BEGIN_SRC c
  sleep (caddr_t chan, int pri)
  {
	  register struct proc *rp = u.u_procp;
	  register int s, op;
	  if (pri > PZERO) {
		  if (issig()) goto psig;
		  spl(CLINHB);
		  rp−>p_wchan = chan;
		  rp−>p_stat = SSLEEP;
		  rp−>p_pri = pri;
		  spl(NORMAL);
		  if (runin != 0) {
			  runin = 0;
			  wakeup(&runin);
		  }
		  swtch();
		  if (issig()) goto psig ;
	  } else {
		  spl (CLINHB) ;
		  rp−>p_wchan = chan ;
		  rp−>p_stat = SSLEEP;
		  rp−>p_pri = pri ;
		  spl(NORMAL) ;
		  swtch();
	  }
	  return;

	  /*
	   If priority was low (>PZERO) and there
	   has been a signal, execute non−local
	   goto to the qsav location.
	  ,*/
  psig:
	  aretu(u.u_qsav);
  }
#+END_SRC


** Commutation

Le registre horloge a été inventé pour le temps partagé.

Il existe un processeur spécifique, tout petit, avec son propre quartz, qui décrémente le registre horloge (Programmable Interval Timer) à une périodicité connue.

en plus de ça, dans les OS modernes, on a une interruption horloge matérielle qui interrompt le processus à des intervalles de temps fixe (les tics, jiffy dans le cas de Linux), qui est une fraction de quantum : on ne commute pas, c'est juste pour traiter les alarmes.

Un quantum peut s'exprimer en tics (en général, 10 tics).

*** Algorithme sous unix

On se rapproche d'un système de round robin, mais pas un vrai round robin au sens où il n'y a pas de queue.

p_usrpri = PUSER + p_cpu/4 + 2*p_nice
p_cpu = p_cpu * decay
decay = 1/2 System V Release 3
decay = (2 * load) / (2*load +1) BSD


Version System 5 (avec un decay fixe)
Quand on a trop peu de processus, ça monte trop vite vers 127
Quand on a trop de processus, ça descend trop vite vers PUSER

On pourrait ne plus distinguer entre les processus.

BSD s'est permis d'inventer un decay dynamique.

On privilégie les jobs les plus courts : un vrai round robin rendrait les 'ls' très lents. Ce système booste les nouveaux processus.

Ce qui est dit ici n'est vrai que pour les processus utilisateurs : les processus démon ou noyau ne fonctionnent pas comme ça.

**** Trouver les processus le plus prioritaire

32 listes de processus prêts :
- La liste des processus de priorité 0 à 3
- La liste des processus de priorité 4 à 7
etc...

whichqs (4 octets) : un vecteur de 32 bits qui donne son ième bit à 1 si il y a un processus prêt dans la ième liste.

**** La commutation elle-même

Retirer le processus prioritaire de la tête.

Sauvegarder le PCB du processus courant (présent dans la zone U)
Changer la valeur du registre de la table des pages (proc.p_addr) : où est la table des pages.
Charger les registres du processus élu à partir de la zone U


* Cours 5 : 14/10/2019

Un cours un peu spécial, assuré par Julien Sopena, qui remplace Pierre Sens au pied levé.

On anticipe sur un certain nombre de choses qui seront plutôt vues au deuxième semestre.
On reprend aussi un certain nombre, d'aphorismes, et d'explications sur des choses supposées connues pour l'évaluation de cette UE.

*** Temps réel

#+BEGIN_DEFINITION
On dit qu'une application est en *temps réel* sssi on peut garantir, de manière déterministe, que son temps d'exécution est en-dessous d'une certaine valeur. En particulier, ne signifie pas forcément rapide. L'idée est qu'on ne définit pas en probabilité le temps d'exécution, mais qu'il est donné de manière déterministe.
#+END_DEFINITION

Quelles sont les multiples sources d'aléatoire dans le temps d'exécution d'une application, sur lequel le programmeur n'a pas d'influence ?

- L'ordonnanceur, qui fait ce qu'il veut, et dont il est toujours bon de supposer qu'il joue contre nous.
- Les verrous que n'importe quelle autre application aura jugé bon de prendre.
- Les entrées-sorties, et les queues pour l'obtention du contrôleur d'entrées/sorties.
- Les contentieux sur le contrôleur mémoire.

La difficulté est énorme, on le voit. Si on suppose ne pas avoir de problème avec les éléments mentionnés plus haut, il reste un certain nombre de choses qui posent problème :
- On doit avoir un code invariant en les données.
- On doit avoir un code fini (évident), soit un nombre d'instructions toujours fini quel que soit le résultats des branchements.
- On doit avoir une spécification exacte du matériel (impossible dans les faits) pour pouvoir traduire une durée en nombre d'instructions en une durée en temps humain.

Le but d'un fournisseur d'une application temps réel est de fournir, en plus de cette application, un WCET (Worst Case Execution Time).

Unix (au moins la version 6 qu'on voit en TD) n'est pas un système temps-réel.
On a un certain nombre de noyaux temps réel, par exemple :

SVR4, SVR5 (dans lesquels l'échelle des priorités est dans l'autre sens que UNIX), et dans lesquels on a trois niveaux de priorité croissantes : Utilisateur, noyau, temps réel

#+BEGIN_THEOREM
Dans UNIX v6 (celui vu en TD), *on ne peut pas s'endormir en mode utilisateur*.
#+END_THEOREM

#+BEGIN_PROOF
On a fondamentalement qu'une seule manière de s'endormir, qu'on le veuille ou non : c'est la fonction noyau sleep (à ne pas confondre avec l'appel système sleep(3), qui n'est qu'une des manière d'accéder à cette fonction noyau).

Or, si cette fonction noyau est exécutée, c'est bien qu'on est en mode noyau. Donc quand le processus s'endort effectivement, c'est au milieu de cette fonction noyau, donc pas en mode utilisateur.

Après, les manière d'accéder à cette fonction diffèrent. Celle-ci endort toujours la fonction appelante (il n'y a de toute façon que deux paramètres : la priorité à laquelle on s'endort, et l'adresse à laquelle on s'endort). On peut par exemple appeler l'appel système sleep(3) de sa propre volition, ou une interruption peut nous amener en mode noyau pour nous faire exécuter sleep.
#+END_PROOF

#+BEGIN_DEFINITION
Dans UNIX v6, on distingue trois grandes plages de priorité :
- Plus de 100, les processus utilisateur
- Entre 0 et 100, les processus en mode noyau réveillables et swappables
- En-dessous de 0, les processsus en mode noyau non-réveillables et non-swappables
#+END_DEFINITION

Quantum en temps partagé est inversement proportionnel à la priorité : tâches très longues (batch) qui gagneront peu d'élections, mais qui resteront longtemps, contre des applications interactives qui auront un quantum faible mais une haute priorité.

#+BEGIN_THEOREM
On se met dans une situation où on suppose une petite tâche dont le temps total d'exécution est négligeable devant celui d'un certain nombre n de grosses tâches. On suppose un vrai système de tourniquet où les tâches sont toutes considérées à égalité.

Si un quantum est suffisemment petit devant le temps d'exécution de la petite tâche, alors le temps avant la fin de l'exécution de cette petite tâche ne dépend pas de la durée des grandes, mais uniquement de leur nombre.

On veut donc faire des petits quanta, mais pas trop petits non plus : la commutation prenant un temps constant, il convient de ne pas trop augmenter son coût devant celui des "vraies" tâches.
#+END_THEOREM

Pour pouvoir implémenter un système temps réel, on rajoute un champ dans la structure proc qui note la plage de priorité (utilisateur, noyau, ou temps réel).

Les tâches temps réel rajoutent une flèche dans l'automate des états du processus.

L'idée est de laisser la place à la tâche temps-réel (mais le noyau unix v6 n'est pas préemptif) : ça n'est pas possible en l'état.

#+BEGIN_DEFINITION
*Un processus est exactement défini par un espace d'adressage.*

Un noyau non préemptif signifie qu'on ne peut changer d'espace d'adressage qu'en cas d'ordonnancement.
#+END_DEFINITION

#+BEGIN_THEOREM
Un noyau temps réel est nécessairement préemptif.
#+END_THEOREM

#+BEGIN_DEFINITION
La définition générale d'un processus est l'exécution d'une tâche.
#+END_DEFINITION

#+BEGIN_THEOREM
Dans un noyau non préemptif, il n'y a que deux manière de quitter le processeur :
- if(runrun)
- sleep()
#+END_THEOREM

Deux solutions :

- La première consiste à implémenter une espèce de quantum bis à fréquence plus haute, qu'on appellerait "point de réquisition", qui ne déboucherait sur une action que si un processus temps réel est prêt.
- Rendre le noyau préemptif.

Le première solution va quand même amener des temps de latence assez élevés, il est en pratique assez compliqué de mettre ces points de réquisition fréquemment.

La deuxième solution va amener tout un tas d'autres problèmes : si le noyau est préemptif, on peut se faire voler le processeur à tout moment (en vrai, c'est vrai en général, si on remplace "à tout moment" par "à la prochaine élection"). On a intérêt à protéger les variables qu'on manipule si elles sont partagées. Notion de verrou.

Or le verrou ne tient pas compte des priorités. Si un processus de basse priorité a pris un verrou, même le processus temps réel doit attendre que le verrou soit libéré pour continuer son exécution.

Ce verrou ne posait pas de problème pour un noyau non-temps réel, vu qu'on n'avait pas à garantir quelque temps d'exécution au pire cas que ce soit.

Solution est la propagation de la priorité temps-réel : si un processus de basse priorité a acquis un verrou et qu'un processus temps réel se pointe, la priorité temps réel est conféré au processus basse priorité pour qu'il puisse vite rendre le verrou.

#+BEGIN_DEFINITION
Dormir, c'est ne pas participer à l'élection.
Se réveiller, c'est être candidat à la prochaine élection.
#+END_DEFINITION

#+BEGIN_DEFINITION
L'appel système est une interruption volontaire.
#+END_DEFINITION

#+BEGIN_DEFINITION
On définit un fil d'exécution par une pile (ses données, plus précisément), un pointeur de pile et un pointeur d'instructions.

Le fil d'exécution (thread) habite dans un espace d'adressage. On voit immédiatement comment on peut avoir plusieurs fils d'exécution dans un processus : il suffit juste d'avoir plusieurs triplets (pile, pointeur de pile, pointeur d'instruction) définis dans le même espace d'adressage.
#+END_DEFINITION


* Cours 6 : 21/10/2019

** Gestion des processus, ordonnancement, préemption

Dans linux (post 2.6), on ne fait plus la distinction entre proc et user, distinction qui venait des pressions mémoires.

Tout est dans la structure task, union des deux précédentes.

Dans la structure task, on trouvera :
- La politique d'ordonnancement (OTHER pour les processus normaux, anciennement une espèce de round robin avec vieillissement (cf. unix et son algo de decay), mais maintenant selon le CFS, FIFO réservé pour les tâches temps réel en mode batch , RR sans vieillissement pour les tâches en temps réel partagé) : spécifié par la norme POSIX.
- Leur état dans l'automate
- priority : priorité de base
- counter : remplace p_cpu (à ceci près que ça compte le nombre de ticks restants avant la prochaine commu)
- contexte mémoire
- descripteurs de fichiers ouverts

L'ordonnanceur considère des threads (pas des processus : on dira processus dans la suite, par abus de langage), qui partagent la même espace d'adressage (la structure mm, pour memory management, qui contient entre autres la table des pages).

C'est le déchargement/chargement de la table des pages qui coûte cher dans la commutation -> et en plus invalidation des caches.

Trois classes de processus dans les linux récents :
- Interactifs : peu prioritaires, peu coûteux en CPU, mais ont tendance à faire beaucoup d'entrées-sorties. Les processus de l'utilisateur sont de ce type. (Ces processus suivent en général la politique d'ordonnancement SCHED_OTHER)
- Batch (peut être utilisé pour le temps réel, mais ne peut être préempté que par un processus de priorité plus grande que lui) : Ce sont des tâches qui ne se font pas en temps partagé : une fois qu'elles ont commencé, elles vont jusqu'au bout (en général, batch veut dire sans temps partagé) (Ces processus suivent la politique d'ordonnancement SCHED_FIFO)
- Temps-réel mais avec partage de temps, sans decay (Ces processus suivent la politique SCHED_RR) 

#+BEGIN_QUOTE
SCHED_FIFO is a simple scheduling algorithm without time slicing.

Man page, sched(7)
#+END_QUOTE

#+BEGIN_QUOTE
SCHED_RR: Round-robin scheduling

SCHED_RR is a simple enhancement of SCHED_FIFO. Everything described above for SCHED_FIFO also applies to
SCHED_RR, except that each thread is allowed to run only for a maximum time quantum. If a SCHED_RR thread
has been running for a time period equal to or longer than the time quantum, it will be put at the end of
the list for its priority. A SCHED_RR thread that has been preempted by a higher priority thread and subse‐
quently resumes execution as a running thread will complete the unexpired portion of its round-robin time
quantum. The length of the time quantum can be retrieved using sched_rr_get_interval(2).

Suite de la man page, sched(7)
#+END_QUOTE

Jusqu'en 2.4, linux restait non-préemptif : on avait deux classes d'ordonnancements :
- statique sans vieillissement (pour les processus temps réel, priorité choisie par l'utilisateur, RR)
- dynamique, selon l'algorithme proche du unix avec decay.

*** Algo de epoch (pour OTHER)

[[./CM1/epoch.jpg][Algorithme de epoch]]

*** Schedule()

Appelée en cas de blocage du processus courant, ou bien au retour en mode U si un flag (runrun) est mis.

Choisit le meilleur candidat, selon le concept de poids :
- Poids = 1000 + priorité base pour SCHED_RR
- Poids = counter + priorité de base pour SCHED_OTHER
- Poids = 0 si counter = 0

Si tous les processus prêts ont un poids de 0, on est à la fin de la période.

Tous les processus voient leurs counter initialisés.
counter = counter/2 + priority

fork() divise le temps du père à égalité entre le père et le fils.

L'idée est de connaître exactement la taille maximale d'une époque au début de celle-ci : on aura beau créer autant de processus qu'on veut, la taille de l'époque ne saurait dépasser la taille maximale qu'on pouvait calculer au début de celle-ci.

On sait surtout que tous les processus prêts se verront donner du temps avant la fin de l'époque.

*** SMP

Une espèce d'ordonnanceur plus compliqué, pour la prise en compte des processeurs multiples à cache séparé : fondamentalement, il est moins coûteux de garder un processus sur le même processus, ça évite d'avoir à invalider les caches.

Comment changer l'algo de manière à privilégier le fait de laisser les processus plutôt sur les mêmes processeurs, et faire varier ce privilège en fonction de la taille des caches ? [réponse en M2]

*** Ordonnancement 2.6

Tic (jiffy) plus bas, alarmes plus précises.

On a deux grandes classes de processus
- Processus avec beaucoup d'E/S
- Processus calcul

Système de bonus/malus en fonction du temps qu'on est passé endormi pour des entrées/sorties.

Pour ça, dans la structure task, on ajoute un champ.

*** Linux préemptif

On attend le point stable du noyau (preempt_count == 0) pour retourner en mode noyau.

La variable preempt_count est incrémentée avec la prise des verrous et décrémentée avec leur libération.

runrun s'appelle maintenant need_resched (booléen).

On a des vérifications régulières de need_resched (points de réquisition).

Ordonnancement préemptif : temps partagé (par opposition au mode batch)
Diffère de noyau préemptif, qui signifie qu'on peut avoir une commutation avant une fin de quantum.

*** Completely Fair Scheduler

Temps virtuel d'exécution :
Temps d'exécution qu'elles ont consommé lors de leur dernière exécution.
Avantage mécaniquement les processus qui font beaucoup d'entrées-sorties.

Arbre rouge-noir est un bon compromis entre rapidité et gestion de la dynamicité : la structure dépend de l'ordre d'insertion.

Apparemment, le stockage des pages mémoire est aussi implémentée via des arbres rouge-noirs.

La mise à jour du virtual runtime requiert de bouger une feuille dans un arbre rouge-noir :
2log(n) soit O(log(n)).


** Les entrées-sorties

*** Le cache tampon

Chaque fois qu'on fait read ou write, le bloc dans lequel se trouve l'octet qui intéresse est copié dans une zone noyau de la mémoire centrale, appelée le cache tampon.

En fait, le processeur ne connaît pas directement le disque.

Le cache tampon est bien évidemment dans la partie noyau de la mémoire centrale.

La structure buf est en fait une table de hash.


* Annexes

Support de cours :

[[./CM1/cours1.pdf][Cours 1]]
[[./CM2/cours2.pdf][Cours 2]]


